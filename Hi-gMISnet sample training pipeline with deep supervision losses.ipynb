{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 14:03:58.903464: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-19 14:03:59.623140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda-11.8/lib64:\n",
      "2024-11-19 14:03:59.623209: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda-11.8/lib64:\n",
      "2024-11-19 14:03:59.623215: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import natsort\n",
    "import pywt\n",
    "import albumentations as A\n",
    "from PIL import Image, ImageOps\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import zeros, ones\n",
    "from numpy.random import randint\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models, Input\n",
    "from tensorflow.keras.applications import VGG16, DenseNet201\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, Conv2DTranspose, LeakyReLU, Activation, Concatenate, concatenate, Dropout, \n",
    "    BatchNormalization, MaxPooling2D, UpSampling2D, GlobalAveragePooling2D, Multiply, ELU, add\n",
    ")\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import get_custom_objects, plot_model\n",
    "from tensorflow.image import ssim\n",
    "# from tensorflow_wavelets.utils.helpers import *\n",
    "from datetime import datetime \n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # for tensor flow warning\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Define a global variable for random seed\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters (Learning rate, Scheduler, etc.) need to be optimized per dataset to get the best results. Use tensorflow version 2.8.4 and python version 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWT pooling and Convolution Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T18:23:06.246803Z",
     "iopub.status.busy": "2024-09-14T18:23:06.246471Z",
     "iopub.status.idle": "2024-09-14T18:23:06.344215Z",
     "shell.execute_reply": "2024-09-14T18:23:06.343243Z",
     "shell.execute_reply.started": "2024-09-14T18:23:06.246769Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# DWT pooling and Convolution Block\n",
    "\n",
    "class DWT(layers.Layer):\n",
    "    def __init__(self, wavelet_name='haar', concat=1, **kwargs):\n",
    "        super(DWT, self).__init__(**kwargs)\n",
    "        # self._name = self.name + \"_\" + name\n",
    "        # get filter coeffs from 3rd party lib\n",
    "        wavelet = pywt.Wavelet(wavelet_name)\n",
    "        self.dec_len = wavelet.dec_len\n",
    "        self.concat = concat\n",
    "        # decomposition filter low pass and hight pass coeffs\n",
    "        db2_lpf = wavelet.dec_lo\n",
    "        db2_hpf = wavelet.dec_hi\n",
    "\n",
    "        # covert filters into tensors and reshape for convolution math\n",
    "        db2_lpf = tf.constant(db2_lpf[::-1])\n",
    "        self.db2_lpf = tf.reshape(db2_lpf, (1, wavelet.dec_len, 1, 1))\n",
    "\n",
    "        db2_hpf = tf.constant(db2_hpf[::-1])\n",
    "        self.db2_hpf = tf.reshape(db2_hpf, (1, wavelet.dec_len, 1, 1))\n",
    "\n",
    "        self.conv_type = \"VALID\"\n",
    "        self.border_padd = \"SYMMETRIC\"\n",
    "        self.wavelet_name = wavelet_name\n",
    "        self.concat = concat\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # filter dims should be bigger if input is not gray scale\n",
    "        if input_shape[-1] != 1:\n",
    "            # self.db2_lpf = tf.repeat(self.db2_lpf, input_shape[-1], axis=-1)\n",
    "            self.db2_lpf = tf.keras.backend.repeat_elements(self.db2_lpf, input_shape[-1], axis=-1)\n",
    "            # self.db2_hpf = tf.repeat(self.db2_hpf, input_shape[-1], axis=-1)\n",
    "            self.db2_hpf = tf.keras.backend.repeat_elements(self.db2_hpf, input_shape[-1], axis=-1)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "\n",
    "        # symmetric column padding\n",
    "        inputs_pad = tf.pad(inputs, [[0, 0], [0, 0], [self.dec_len-1, self.dec_len-1], [0, 0]], self.border_padd)\n",
    "\n",
    "        # approximation conv only rows\n",
    "        a = tf.nn.conv2d(\n",
    "            inputs_pad, self.db2_lpf, padding=self.conv_type, strides=[1, 1, 1, 1], name=\"row_approx\"\n",
    "        )\n",
    "        # details conv only rows\n",
    "        d = tf.nn.conv2d(\n",
    "            inputs_pad, self.db2_hpf, padding=self.conv_type, strides=[1, 1, 1, 1], name=\"row_detail\"\n",
    "        )\n",
    "        # ds - down sample\n",
    "        a_ds = a[:, :, 1:a.shape[2]:2, :]\n",
    "        d_ds = d[:, :, 1:d.shape[2]:2, :]\n",
    "\n",
    "        # symmetric row padding\n",
    "        a_ds_pad = tf.pad(a_ds, [[0, 0], [self.dec_len-1, self.dec_len-1], [0, 0], [0, 0]], self.border_padd)\n",
    "        d_ds_pad = tf.pad(d_ds, [[0, 0], [self.dec_len-1, self.dec_len-1], [0, 0], [0, 0]], self.border_padd)\n",
    "\n",
    "        # convolution is done on the rows so we need to\n",
    "        # transpose the matrix in order to convolve the colums\n",
    "        a_ds_pad = tf.transpose(a_ds_pad, perm=[0, 2, 1, 3])\n",
    "        d_ds_pad = tf.transpose(d_ds_pad, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # aa approximation approximation\n",
    "        aa = tf.nn.conv2d(\n",
    "            a_ds_pad, self.db2_lpf, padding=self.conv_type, strides=[1, 1, 1, 1], name=\"LL\"\n",
    "        )\n",
    "        # ad approximation details\n",
    "        ad = tf.nn.conv2d(\n",
    "            a_ds_pad, self.db2_hpf, padding=self.conv_type, strides=[1, 1, 1, 1], name=\"LH\"\n",
    "        )\n",
    "        # ad details aproximation\n",
    "        da = tf.nn.conv2d(\n",
    "            d_ds_pad, self.db2_lpf, padding=self.conv_type, strides=[1, 1, 1, 1], name=\"HL\"\n",
    "        )\n",
    "        # dd details details\n",
    "        dd = tf.nn.conv2d(\n",
    "            d_ds_pad, self.db2_hpf, padding=self.conv_type, strides=[1, 1, 1, 1], name=\"HH\"\n",
    "        )\n",
    "\n",
    "        # transpose back the matrix\n",
    "        aa = tf.transpose(aa, perm=[0, 2, 1, 3], name=\"LL\")\n",
    "        ad = tf.transpose(ad, perm=[0, 2, 1, 3], name=\"LH\")\n",
    "        da = tf.transpose(da, perm=[0, 2, 1, 3], name=\"HL\")\n",
    "        dd = tf.transpose(dd, perm=[0, 2, 1, 3], name=\"HH\")\n",
    "\n",
    "        # down sample\n",
    "        ll = aa[:, 1:aa.shape[1]:2, :, :]\n",
    "        lh = ad[:, 1:ad.shape[1]:2, :, :]\n",
    "        hl = da[:, 1:da.shape[1]:2, :, :]\n",
    "        hh = dd[:, 1:dd.shape[1]:2, :, :]\n",
    "\n",
    "        # concate all outputs ionto tensor\n",
    "        if self.concat == 0:\n",
    "            x = tf.concat([ll, lh, hl, hh], axis=-1, name=\"LL_LH_HL_HH\")\n",
    "        elif self.concat == 2:\n",
    "            x = ll\n",
    "        elif self.concat ==1:\n",
    "            return ll,lh,hl,hh\n",
    "        else:\n",
    "            x = tf.concat([tf.concat([ll, lh], axis=1), tf.concat([hl, hh], axis=1)], axis=2, name=\"LL_LH-HL_HH\")\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DWT, self).get_config()\n",
    "        config.update({'wavelet_name': self.wavelet_name, 'concat': self.concat})\n",
    "        return config\n",
    "\n",
    "# Post wavelet conv block\n",
    "def wavelet_conv_block(x, in_channels,name_prefix=''):\n",
    "\n",
    "    _np = name_prefix\n",
    "\n",
    "    if _np != '':\n",
    "        _np = _np + '_'\n",
    "\n",
    "    ll, lh, hl, hh = DWT(concat=1)(x)\n",
    "    \n",
    "    y = tf.concat([ll, lh, hl, hh], axis=3)\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(in_channels * 2, kernel_size=1, dilation_rate=1, padding='valid', name=_np+'Post-DWT-in-c1')(y)\n",
    "    conv2 = tf.keras.layers.Conv2D(in_channels, kernel_size=3, dilation_rate=1, padding='same', name=_np+'Post-DWT-c1-c2')(conv1)\n",
    "    conv2 = tf.keras.layers.BatchNormalization(name=_np+'Post-DWT-c2-bn2')(conv2,training=True)\n",
    "    conv2 = tf.keras.layers.ReLU(name=_np+'Post-DWT-bn2-r2')(conv2)\n",
    "\n",
    "    \n",
    "    conv3 = tf.keras.layers.Conv2D(in_channels, kernel_size=5, dilation_rate=1, padding='same', name=_np+'Post-DWT-c1-c3')(conv1)\n",
    "    conv3 = tf.keras.layers.BatchNormalization(name=_np+'Post-DWT-c3-bn3')(conv3,training=True)\n",
    "    conv3 = tf.keras.layers.ReLU(name=_np+'Post-DWT-bn3-r3')(conv3)\n",
    "    \n",
    "    conv4 = tf.keras.layers.Conv2D(in_channels * 2, kernel_size=1, dilation_rate=1, padding='valid',\n",
    "    name= _np + 'Post-DWT-r2_r3-out0')(tf.concat([conv2, conv3], axis=3))\n",
    "    \n",
    "    return conv4, ll, lh, hl, hh   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dual-mode Attention Gate (DAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T18:23:06.348755Z",
     "iopub.status.busy": "2024-09-14T18:23:06.348467Z",
     "iopub.status.idle": "2024-09-14T18:23:06.383146Z",
     "shell.execute_reply": "2024-09-14T18:23:06.38238Z",
     "shell.execute_reply.started": "2024-09-14T18:23:06.348729Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def conv_block(x, filter_size, size, dropout, batch_norm=False, name_prefix=''):\n",
    "    \n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\", name=name_prefix + '_in-c1')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3, name=name_prefix + '_c1-bn1')(conv,training=True)\n",
    "        conv = layers.ReLU(name=name_prefix + '_bn1-r1')(conv)\n",
    "    else:\n",
    "        conv = layers.ReLU(name=name_prefix + '_c1-r1')(conv)\n",
    "\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\", name=name_prefix + '_r1-c2')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3, name=name_prefix + '_c2-bn2')(conv,training=True)\n",
    "        conv = layers.ReLU(name=name_prefix + '_bn2-r2')(conv) \n",
    "    else:\n",
    "        conv = layers.ReLU(name=name_prefix + '_c2-r2')(conv)  \n",
    "    \n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout, name=name_prefix + '_r2-out0')(conv)\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "def repeat_elem(tensor, rep):\n",
    "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),arguments={'repnum': rep})(tensor)\n",
    "\n",
    "\n",
    "def res_conv_block(x, filter_size, size, dropout, batch_norm=False, name_prefix=''):\n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same', name=name_prefix + '_in-c1')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3, name=name_prefix + '_c1-bn1')(conv,training=True)\n",
    "        conv = layers.ReLU(name=name_prefix + '_bn1-r1')(conv)\n",
    "    else:\n",
    "        conv = layers.ReLU(name=name_prefix + '_c1-r1')(conv)\n",
    "    \n",
    "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same', name=name_prefix + '_r1-c2')(conv)\n",
    "    _ostr2 = 'c2'\n",
    "    if batch_norm is True:\n",
    "        conv = layers.BatchNormalization(axis=3, name=name_prefix + '_c2-bn2')(conv,training=True)\n",
    "        _ostr2 = 'bn2'\n",
    "\n",
    "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
    "    if dropout > 0:\n",
    "        conv = layers.Dropout(dropout, name=name_prefix+'_'+_ostr2+'-do2')(conv)\n",
    "        _ostr2 = 'do1'\n",
    "\n",
    "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same', name=name_prefix + '_in-c3')(x)\n",
    "    _ostr3 = 'c3'\n",
    "    if batch_norm is True:\n",
    "        shortcut = layers.BatchNormalization(axis=3, name=name_prefix + '_c3-bn3')(shortcut,training=True)\n",
    "        _ostr3 = 'bn3'\n",
    "    \n",
    "    res_path = layers.add([shortcut, conv], name=name_prefix + '_'+_ostr3+'_'+_ostr2+'-add1')\n",
    "    res_path = layers.ReLU(name=name_prefix + '_'+_ostr3+'_'+_ostr2+'-out0')(res_path)  #Activation after addition with shortcut (Original residual block)\n",
    "    return res_path\n",
    "\n",
    "def gating_signal(input, out_size, batch_norm=False):\n",
    "    init = RandomNormal(stddev=0.02, seed=seed)\n",
    "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
    "    if batch_norm:\n",
    "        x = layers.BatchNormalization(axis=3)(x,training=True)\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def attention_block(x, gating, inter_shape, name_prefix=''):\n",
    "    filters = x.shape[-1]\n",
    "    filtersg = gating.shape[-1]\n",
    "    shape_x = K.int_shape(x)\n",
    "    shape_g = K.int_shape(gating)\n",
    "    init = RandomNormal(stddev=0.02, seed=seed)\n",
    "    xa = x[:, :, :, :filters // 2]\n",
    "    xb = x[:, :, :, filters // 2: ]\n",
    "    gating_a = gating[:, :, :, :filtersg // 2]\n",
    "    gating_b = gating[:, :, :, filtersg // 2:]\n",
    "# Getting the x signal to the same shape as the gating signal\n",
    "    theta_xa = layers.Conv2D(inter_shape//2, (2, 2), strides=(2, 2), padding='same',name=name_prefix + 'theta_a')(xa)  # 16\n",
    "    shape_theta_xa = K.int_shape(theta_xa)\n",
    "    theta_xb = layers.Conv2D(inter_shape//2, (2, 2), strides=(2, 2), padding='same',name=name_prefix + 'theta_b')(xb)  # 16\n",
    "    shape_theta_xb = K.int_shape(theta_xb)\n",
    "# Getting the gating signal to the same number of filters as the inter_shape\n",
    "    phi_ga = layers.Conv2D(inter_shape//2, (1, 1), padding='same')(gating_a)\n",
    "    upsample_ga = layers.Conv2DTranspose(inter_shape//2, (3, 3),strides=(shape_theta_xa[1] // shape_g[1], shape_theta_xa[2] // shape_g[2]),padding='same',name=name_prefix + 'phi_ga')(phi_ga)  # 16\n",
    "    phi_gb = layers.Conv2D(inter_shape//2, (1, 1), padding='same')(gating_b)\n",
    "    upsample_gb = layers.Conv2DTranspose(inter_shape//2, (3, 3),strides=(shape_theta_xb[1] // shape_g[1], shape_theta_xb[2] // shape_g[2]),padding='same',name=name_prefix + 'phi_gb')(phi_gb)  # 16\n",
    "    \n",
    "    \n",
    "    ###################################################\n",
    "    concat_xg = layers.add([theta_xa,upsample_ga ],name=name_prefix + 'foreground_add')\n",
    "    act_xg = layers.ReLU()(concat_xg)\n",
    "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
    "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
    "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
    "    upsample_psi1 = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]),name=name_prefix + 'visual_fore')(sigmoid_xg)  # 32\n",
    "\n",
    "    upsample_psi = repeat_elem(upsample_psi1, xa.shape[3])\n",
    "    ya = layers.multiply([upsample_psi, xa],name=name_prefix + 'foreground_out')\n",
    "\n",
    "    \n",
    "    ##################################################\n",
    "    subtract_xg = layers.subtract([theta_xb,upsample_gb],name=name_prefix + 'background_add')\n",
    "    sub_act_xg = layers.ReLU()(subtract_xg)\n",
    "    sub_psi = layers.Conv2D(1, (1, 1), padding='same')(sub_act_xg)\n",
    "    sub_sigmoid_xg = layers.Activation('sigmoid',name=name_prefix + 'before_reverse')(sub_psi)\n",
    "    sub_sigmoid_xg = -1 * (sub_sigmoid_xg) + 1\n",
    "    sub_upsample_psi1 = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]),name=name_prefix +'visual_back' )(sub_sigmoid_xg)  # 32\n",
    "    sub_upsample_psi = repeat_elem(sub_upsample_psi1, xb.shape[3])\n",
    "    yb = layers.multiply([sub_upsample_psi, xb],name=name_prefix + 'background_out')\n",
    "    ##################################################\n",
    "    y = layers.Concatenate(axis=3)([ya, yb])\n",
    "\n",
    "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
    "    result_bn = layers.BatchNormalization(axis=3)(result,training=True)\n",
    "    result_bn = layers.ReLU(name=name_prefix + 'attention_out')(result_bn)\n",
    "    return result_bn,upsample_psi1,sub_upsample_psi1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T18:23:06.38486Z",
     "iopub.status.busy": "2024-09-14T18:23:06.38457Z",
     "iopub.status.idle": "2024-09-14T18:23:06.423074Z",
     "shell.execute_reply": "2024-09-14T18:23:06.422157Z",
     "shell.execute_reply.started": "2024-09-14T18:23:06.384832Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1),activation='relu', name_prefix='cbn'):\n",
    "\n",
    "    init = RandomNormal(stddev=0.02, seed=seed)\n",
    "    _in = ''\n",
    "    _out = 'in1'\n",
    "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding,kernel_initializer=init, name=name_prefix + \"-\" + _in + \">\" + _out)(x)\n",
    "    _in = _out\n",
    "\n",
    "    if(activation == None):\n",
    "        _out = 'out1'\n",
    "        x = BatchNormalization(axis=3, name=name_prefix + \"-\" + _in + \">\" + _out)(x, training=True)\n",
    "    else:\n",
    "        _out = 'bn1'\n",
    "        x = BatchNormalization(axis=3, name=name_prefix + \"-\" + _in + \">\" + _out)(x, training=True)\n",
    "        _in = _out\n",
    "        _out = 'out1'\n",
    "        x = Activation(activation, name=name_prefix + \"-\" + _in + \">\" + _out)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None,dropout=True):\n",
    "\n",
    "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization(axis=3)(x,training=True)\n",
    "    if dropout:\n",
    "        x = Dropout(0.5)(x, training=True)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def MultiResBlock(U, inp, alpha = 1.67, name_prefix='mrb'):\n",
    "\n",
    "    W = alpha * U\n",
    "\n",
    "    shortcut = inp\n",
    "\n",
    "    _in = 'in1'\n",
    "    _out = 'cbn1'\n",
    "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
    "                         int(W*0.5), 1, 1, activation=None, padding='same', name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'in1'\n",
    "    _out = 'cbn2'\n",
    "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
    "                        activation='relu', padding='same', name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'cbn2'\n",
    "    _out = 'cbn3'\n",
    "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
    "                        activation='relu', padding='same', name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'cbn3'\n",
    "    _out = 'cbn4'\n",
    "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
    "                        activation='relu', padding='same', name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'cbn2-cbn3-cbn4'\n",
    "    _out = 'concat1'\n",
    "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3, name=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    _in = 'concat1'\n",
    "    _out = 'bn1'\n",
    "    out = BatchNormalization(axis=3, name=name_prefix + \"-\" + _in + \">\" + _out)(out,training=True)\n",
    "\n",
    "    _in = 'in1-bn1'\n",
    "    _out = 'add1'\n",
    "    out = add([shortcut, out], name=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    _in = 'add1'\n",
    "    _out = 'r1'\n",
    "    out = Activation('relu', name=name_prefix + \"-\" + _in + \">\" + _out)(out)\n",
    "    _in = 'r1'\n",
    "    _out = 'out1'\n",
    "    out = BatchNormalization(axis=3, name=name_prefix + \"-\" + _in + \">\" + _out)(out,training=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "def ResPath(filters, length, inp, name_prefix='rp'):\n",
    "\n",
    "    name_block = name_prefix + '_b0'\n",
    "    shortcut = inp\n",
    "    _in = 'in1'\n",
    "    _out = 'cbn1'\n",
    "    shortcut = conv2d_bn(shortcut, filters, 1, 1,activation=None, padding='same', name_prefix=name_block + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'in1'\n",
    "    _out = 'cbn2'\n",
    "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same', name_prefix=name_block + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'cbn1-cbn2'\n",
    "    _out = 'add1'\n",
    "    out = add([shortcut, out], name=name_block + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    _in = 'add1'\n",
    "    _out = 'r1'\n",
    "    out = Activation('relu', name=name_block + \"-\" + _in + \">\" + _out)(out)\n",
    "\n",
    "    _in = 'r1'\n",
    "    _out = 'bn1'\n",
    "    out = BatchNormalization(axis=3, name=name_block + \"-\" + _in + \">\" + _out)(out,training=True)\n",
    "\n",
    "    for i in range(length-1):\n",
    "        name_block = name_prefix + '_b' + str(i+1)\n",
    "        _in = 'in1'\n",
    "        _out = 'cbn1'\n",
    "        shortcut = conv2d_bn(shortcut, filters, 1, 1,activation=None, padding='same', name_prefix=name_block + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "        _in = 'in1'\n",
    "        _out = 'cbn2'\n",
    "        out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same', name_prefix=name_block + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "        _in = 'cbn1-cbn2'\n",
    "        _out = 'add1'\n",
    "        out = add([shortcut, out], name=name_block + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "        _in = 'add1'\n",
    "        _out = 'r1'\n",
    "        out = Activation('relu', name=name_block + \"-\" + _in + \">\" + _out)(out)\n",
    "\n",
    "        _in = 'r1'\n",
    "        _out = 'bn1'\n",
    "        out = BatchNormalization(axis=3, name=name_block + \"-\" + _in + \">\" + _out)(out,training=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "def BasicConv2D(inputs,out_planes, kernel_size, stride=1, padding='same', dilation=1):\n",
    "    conv = tf.keras.layers.Conv2D(\n",
    "            filters=out_planes,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=stride,\n",
    "            padding=padding,\n",
    "            dilation_rate=dilation,\n",
    "            use_bias=False\n",
    "        )(inputs)\n",
    "    bn = tf.keras.layers.BatchNormalization()(conv,training=True)\n",
    "    relu = tf.keras.layers.ReLU()(bn)\n",
    "    return relu\n",
    "\n",
    "def RFBModified(inputs, out_channel):\n",
    "    relu = tf.keras.layers.ReLU()(inputs)\n",
    "\n",
    "    # Define branch0\n",
    "    branch0 = BasicConv2D(relu, out_channel, kernel_size=1)\n",
    "\n",
    "    # Define branch1\n",
    "    conv1_1x1 = BasicConv2D(relu, out_channel, kernel_size=1)\n",
    "    conv1_1x3 = BasicConv2D(conv1_1x1, out_channel, kernel_size=(1, 3), padding='same')\n",
    "    conv1_3x1 = BasicConv2D(conv1_1x3, out_channel, kernel_size=(3, 1), padding='same')\n",
    "    conv1_3x3 = BasicConv2D(conv1_3x1, out_channel, kernel_size=3, padding='same', dilation=3)\n",
    "\n",
    "    # Define branch2\n",
    "    conv2_1x1 = BasicConv2D(relu, out_channel, kernel_size=1)\n",
    "    conv2_1x5 = BasicConv2D(conv2_1x1, out_channel, kernel_size=(1, 5), padding='same')\n",
    "    conv2_5x1 = BasicConv2D(conv2_1x5, out_channel, kernel_size=(5, 1), padding='same')\n",
    "    conv2_3x3 = BasicConv2D(conv2_5x1, out_channel, kernel_size=3, padding='same', dilation=5)\n",
    "\n",
    "    # Define branch3\n",
    "    conv3_1x1 = BasicConv2D(relu, out_channel, kernel_size=1)\n",
    "    conv3_1x7 = BasicConv2D(conv3_1x1, out_channel, kernel_size=(1, 7), padding='same')\n",
    "    conv3_7x1 = BasicConv2D(conv3_1x7, out_channel, kernel_size=(7, 1), padding='same')\n",
    "    conv3_3x3 = BasicConv2D(conv3_7x1, out_channel, kernel_size=3, padding='same', dilation=7)\n",
    "\n",
    "    # Concatenate branches\n",
    "    branches_concat = tf.keras.layers.Concatenate(axis=-1)([branch0, conv1_3x3, conv2_3x3, conv3_3x3])\n",
    "\n",
    "    # Final convolution and residual connection\n",
    "    conv_cat = BasicConv2D(branches_concat, out_channel, kernel_size=3, padding='same')\n",
    "    conv_res = BasicConv2D(relu, out_channel, kernel_size=1)\n",
    "\n",
    "    # Output\n",
    "    output = tf.keras.layers.ReLU()(conv_cat + conv_res)\n",
    "\n",
    "    return output\n",
    "\n",
    "def aggregation(x1, x2, x3):\n",
    "    channel=32\n",
    "    upsample = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')\n",
    "\n",
    "    x1_1 = x1\n",
    "    x1_1_1 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x1_1)\n",
    "    x1_1_2 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x1_1_1)\n",
    "    x2_1_1 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x2)\n",
    "    x2_1 = tf.math.multiply(BasicConv2D(x1_1_1 ,channel, 3, padding='same'), x2)\n",
    "    x3_1 = BasicConv2D(x1_1_2,channel, 3, padding='same') \n",
    "    x3_1 = tf.math.multiply(x3_1 , BasicConv2D(x2_1_1,channel, 3, padding='same'))\n",
    "    x3_1 = tf.math.multiply(x3_1, x3)\n",
    "\n",
    "    x2_2 = tf.concat([x2_1, BasicConv2D(upsample(x1_1),2*channel, 3, padding='same')], axis=-1)\n",
    "    x2_2 = BasicConv2D(x2_2,2 * channel, 3, padding='same')\n",
    "\n",
    "    x3_2 = tf.concat([x3_1, BasicConv2D(upsample(x2_2),2 * channel, 3, padding='same')], axis=-1)\n",
    "    x3_2 = BasicConv2D(x3_2,3 * channel, 3, padding='same')\n",
    "\n",
    "    x = BasicConv2D(x3_2,3 * channel, 3, padding='same')\n",
    "    x = tf.keras.layers.Conv2D(1, 1)(x)\n",
    "    \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T18:23:06.424558Z",
     "iopub.status.busy": "2024-09-14T18:23:06.42422Z",
     "iopub.status.idle": "2024-09-14T18:23:06.438774Z",
     "shell.execute_reply": "2024-09-14T18:23:06.43773Z",
     "shell.execute_reply.started": "2024-09-14T18:23:06.42453Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape, name_prefix='d'):\n",
    "    \n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02, seed=seed) \n",
    "    # source image input\n",
    "    _in = ''\n",
    "    _out = 'in1_pred'\n",
    "    in_src_image = Input(shape=image_shape, name=name_prefix + \"-\" + _in + \">\" + _out) \n",
    "    # target image input\n",
    "    _in = ''\n",
    "    _out = 'in2_gtru'\n",
    "    in_target_image = Input(shape=(512,512,1), name=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    \n",
    "    # concatenate images, channel-wise\n",
    "    _in = 'in1-in2'\n",
    "    _out = 'in1_in2'\n",
    "    merged = Concatenate(\n",
    "        name=name_prefix + \"-\" + _in + \">\" + _out)([in_src_image, in_target_image])\n",
    "    \n",
    "    # C64: 4x4 kernel Stride 2x2\n",
    "    _in = _out\n",
    "    _out = 'c1'\n",
    "    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, name=name_prefix + \"-\" + _in + \">\" + _out)(merged)\n",
    "    _in = _out\n",
    "    _out = 'r1'\n",
    "    d = LeakyReLU(alpha=0.2, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    # C128: 4x4 kernel Stride 2x2\n",
    "    _in = _out\n",
    "    _out = 'c2'\n",
    "    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'r2'\n",
    "    d = LeakyReLU(alpha=0.2, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'bn2'\n",
    "    d = BatchNormalization(name=name_prefix + \"-\" + _in + \">\" + _out)(d) # No training=True?\n",
    "    \n",
    "    # C256: 4x4 kernel Stride 2x2\n",
    "    _in = _out\n",
    "    _out = 'c3'\n",
    "    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'r3'\n",
    "    d = LeakyReLU(alpha=0.2, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'bn3'\n",
    "    d = BatchNormalization(name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    \n",
    "    # C512: 4x4 kernel Stride 2x2 \n",
    "    # Not in the original paper. Comment this block if you want.\n",
    "    _in = _out\n",
    "    _out = 'c4'\n",
    "    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'r4'\n",
    "    d = LeakyReLU(alpha=0.2, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'bn4'\n",
    "    d = BatchNormalization(name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'c5'\n",
    "    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init, name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    _in = _out\n",
    "    _out = 'out1'\n",
    "    patch_out = Activation('sigmoid', name=name_prefix + \"-\" + _in + \">\" + _out)(d)\n",
    "    # define model\n",
    "    model = Model([in_src_image, in_target_image], patch_out)\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.000009, beta_1=0.5)\n",
    "    model.compile(loss='mae', optimizer=opt, loss_weights=[0.5])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T18:23:06.440548Z",
     "iopub.status.busy": "2024-09-14T18:23:06.440232Z",
     "iopub.status.idle": "2024-09-14T18:23:06.485211Z",
     "shell.execute_reply": "2024-09-14T18:23:06.484356Z",
     "shell.execute_reply.started": "2024-09-14T18:23:06.44052Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def define_generator(height, width, n_channels,name_prefix='f_'):\n",
    "\n",
    "    name_prefix = name_prefix + 'g'\n",
    "\n",
    "    _in = ''\n",
    "    _out = 'in1_img'\n",
    "    inputs = Input((height, width, n_channels), name=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    encoder = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    s2 = encoder.get_layer(\"block2_conv2\").output \n",
    "    s3 = encoder.get_layer(\"block3_conv2\").output\n",
    "    s4 = encoder.get_layer(\"block4_conv2\").output\n",
    "    s5 = encoder.get_layer(\"block5_conv2\").output\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    encoder1 = DenseNet201(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    e2 = encoder1.get_layer(\"conv1/relu\").output\n",
    "    e3 = encoder1.get_layer(\"pool2_conv\").output\n",
    "    e4 = encoder1.get_layer(\"pool3_conv\").output\n",
    "    e5 = encoder1.get_layer(\"pool4_conv\").output\n",
    "      \n",
    "    ##############################################################################################\n",
    "\n",
    "    _in = 'in1_img'\n",
    "    _out = 'mrb1'                     \n",
    "    mresblock1 = MultiResBlock(32, inputs, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    _in = 'mrb1'\n",
    "    _out = 'mp1'   \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), name=name_prefix + \"-\" + _in + \">\" + _out)(mresblock1)\n",
    "    _in = 'mrb1'\n",
    "    _out = 'rp1'\n",
    "    mresblock1 = ResPath(32, 4, mresblock1, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    wav_pool256 = DWT(name=\"haar\",concat=0)(inputs)\n",
    "    mresblock2 = Concatenate()([pool1,s2,e2])\n",
    "    _in = 'mp1-vgg1-dnet1'\n",
    "    _out = 'mrb2'\n",
    "    mresblock2 = MultiResBlock(64, mresblock2, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    mresblock2 = Concatenate()([wav_pool256, mresblock2])\n",
    "    _in = 'dwt1_mrb2'\n",
    "    _out = 'mp2'\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), name=name_prefix + \"-\" + _in + \">\" + _out)(mresblock2)\n",
    "    _in = 'dwt1_mrb2'\n",
    "    _out = 'rp2'\n",
    "    mresblock2 = ResPath(64, 3, mresblock2, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    mres_wav_pool256= DWT(concat=2)(mresblock1)\n",
    "    wav_cnn128 = Concatenate(name= name_prefix + 'wav_2_in')([wav_pool256, mresblock2,mres_wav_pool256])\n",
    "    wav_cnn128,_,_,_,_ = wavelet_conv_block(wav_cnn128, 16,name_prefix= name_prefix + 'wav_2')\n",
    "    \n",
    "    wav_out1_ll = DWT(concat=2)(inputs)\n",
    "    wav_pool128 = DWT(concat=0)(wav_out1_ll)\n",
    "    \n",
    "    mresblock3 = Concatenate()([pool2,s3,e3])\n",
    "    _in = 'mp2-vgg2-dnet2'\n",
    "    _out = 'mrb3'\n",
    "    mresblock3 = MultiResBlock(128, mresblock3, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    mresblock3 = Concatenate()([wav_cnn128, mresblock3])\n",
    "    _in = 'dwt2_mrb3'\n",
    "    _out = 'mp3'\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), name=name_prefix + \"-\" + _in + \">\" + _out)(mresblock3)\n",
    "    _in = 'dwt2_mrb3'\n",
    "    _out = 'rp3'\n",
    "    mresblock3 = ResPath(128, 2, mresblock3, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ###############################################\n",
    "    \n",
    "    mres_wav_pool128 = DWT(concat=2)(mresblock2)\n",
    "    wav_cnn64 = Concatenate()([wav_pool128, mresblock3,mres_wav_pool128])\n",
    "    wav_cnn64,_,_,_,_ = wavelet_conv_block(wav_cnn64, 32,name_prefix= name_prefix + 'wav_3')    \n",
    "    \n",
    "    wav_out2_ll = DWT(concat=2)(wav_out1_ll)\n",
    "    wav_pool64 = DWT(concat=0)(wav_out2_ll)\n",
    "\n",
    "    mresblock4= Concatenate()([pool3,s4,e4])\n",
    "    _in = 'mp3-vgg3-dnet3'\n",
    "    _out = 'mrb4'\n",
    "    mresblock4 = MultiResBlock(256, mresblock4, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    mresblock4= Concatenate()([wav_cnn64, mresblock4])\n",
    "    _in = 'dwt3_mrb4'\n",
    "    _out = 'mp4'\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), name=name_prefix + \"-\" + _in + \">\" + _out)(mresblock4)\n",
    "    _in = 'dwt3_mrb4'\n",
    "    _out = 'rp4'\n",
    "    mresblock4 = ResPath(256, 1, mresblock4, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    \n",
    "    \n",
    "    ###############################################\n",
    "    \n",
    "    mres_wav_pool64 = DWT(concat=2)(mresblock3)\n",
    "    wav_cnn32 = Concatenate()([wav_pool64, mresblock4,mres_wav_pool64])\n",
    "    wav_cnn32,_,_,_,_ = wavelet_conv_block(wav_cnn32, 64,name_prefix= name_prefix + 'wav_4')\n",
    "    \n",
    "    mresblock5= Concatenate()([pool4,s5,e5])\n",
    "    _in = 'mp4-vgg4-dnet4'\n",
    "    _out = 'mrb5'\n",
    "    mresblock5 = MultiResBlock(512, mresblock5, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    mresblock5= Concatenate()([wav_cnn32, mresblock5])\n",
    "    _in = 'dwt4_mrb5'\n",
    "    _out = 'mp5'\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2), name=name_prefix + \"-\" + _in + \">\" + _out)(mresblock5)\n",
    "    _in = 'dwt4_mrb5'\n",
    "    _out = 'rp5'\n",
    "    mresblock5 = ResPath(512, 1, mresblock5, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    " \n",
    "    ##############################################################################################\n",
    "\n",
    "    _in = 'mp5'\n",
    "    _out = 'mrb6'\n",
    "    mresblock6 = MultiResBlock(1024, pool5, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ###############################################\n",
    "    \n",
    "    gating_8 = gating_signal(mresblock6, 512, batch_norm=True)\n",
    "    att_8,_,_ = attention_block(mresblock5, gating_8, 512,name_prefix = name_prefix + 'at_1')\n",
    "    up5 = concatenate([trans_conv2d_bn(mresblock6, filters=512, num_row=2, num_col=2, padding='same', strides=(2, 2), dropout=True), att_8], axis=3)\n",
    "    _in = 'up5'\n",
    "    _out = 'mrb7'\n",
    "    mresblock7 = MultiResBlock(512, up5, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    \n",
    "    ###############################################\n",
    "\n",
    "    gating_16 = gating_signal(mresblock7, 256, batch_norm=True)\n",
    "    att_16,_,_ = attention_block(mresblock4, gating_16, 256,name_prefix = name_prefix + 'at_2')\n",
    "    up6 = concatenate([trans_conv2d_bn(mresblock7, filters=256, num_row=2, num_col=2, padding='same', strides=(2, 2), dropout=True), att_16], axis=3)\n",
    "    _in = 'up6'\n",
    "    _out = 'mrb8'\n",
    "    mresblock8 = MultiResBlock(256, up6, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    gating_32 = gating_signal(mresblock8, 128, batch_norm=True)\n",
    "    att_32,at3_fore,at3_back = attention_block(mresblock3, gating_32, 128,name_prefix = name_prefix + 'at_3')\n",
    "    up7 = concatenate([trans_conv2d_bn(mresblock8, filters=128, num_row=2, num_col=2, padding='same', strides=(2, 2), dropout=True), att_32], axis=3)\n",
    "    _in = 'up7'\n",
    "    _out = 'mrb9'\n",
    "    mresblock9 = MultiResBlock(128, up7, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    \n",
    "    ###############################################    \n",
    "    \n",
    "    gating_64 = gating_signal(mresblock9, 64, batch_norm=True)\n",
    "    att_64,at4_fore,at4_back = attention_block(mresblock2, gating_64, 64,name_prefix = name_prefix + 'at_4')\n",
    "    up8 = concatenate([trans_conv2d_bn(mresblock9, filters=64, num_row=2, num_col=2, padding='same', strides=(2, 2), dropout=False), att_64], axis=3)\n",
    "    _in = 'up8'\n",
    "    _out = 'mrb10'\n",
    "    mresblock10 = MultiResBlock(64, up8, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "\n",
    "    ###############################################\n",
    "    \n",
    "    gating_128 = gating_signal(mresblock10, 32, batch_norm=True)\n",
    "    att_128,at5_fore,at5_back = attention_block(mresblock1, gating_128, 32,name_prefix = name_prefix + 'at_5')\n",
    "    up9 = concatenate([trans_conv2d_bn(mresblock10, filters=32, num_row=2, num_col=2, padding='same', strides=(2, 2), dropout=False), att_128], axis=3)\n",
    "    _in = 'up9'\n",
    "    _out = 'mrb11'\n",
    "    mresblock11 = MultiResBlock(32, up9, name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    \n",
    "    ##############################################################################################\n",
    "\n",
    "    init = RandomNormal(stddev=0.02, seed=seed)\n",
    "    _in = 'mrb11'\n",
    "    _out = 'cbn1'\n",
    "    conv10 = conv2d_bn(mresblock11, 1, 1, 1, activation='sigmoid', name_prefix=name_prefix + \"-\" + _in + \">\" + _out)\n",
    "    \n",
    "    x3_rfb=RFBModified(mresblock3,32)\n",
    "    x4_rfb=RFBModified(mresblock4,32)\n",
    "    x5_rfb=RFBModified(mresblock5,32)\n",
    "\n",
    "    ra5_feat = aggregation(x5_rfb,x4_rfb,x3_rfb)\n",
    "\n",
    "    crop_5 = tf.image.resize(ra5_feat, [32,32])\n",
    "    x = -1 * (tf.math.sigmoid(crop_5)) + 1\n",
    "    x = tf.keras.layers.Multiply()([x, mresblock5])\n",
    "    \n",
    "    x = BasicConv2D(x, 256, 1)\n",
    "    x = BasicConv2D(x, 256, 5, padding='same')\n",
    "    x = BasicConv2D(x, 256, 5, padding='same')\n",
    "    x = BasicConv2D(x, 256, 5, padding='same')\n",
    "    ra4_feat = BasicConv2D(x, 1, 1)\n",
    "    x = tf.keras.layers.Add()([ra4_feat, crop_5])\n",
    "    crop_4 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = -1 * (tf.math.sigmoid(crop_4)) + 1\n",
    "    x = tf.keras.layers.Multiply()([x, mresblock4])\n",
    "    x = BasicConv2D(x, 64, 1)\n",
    "    x = BasicConv2D(x, 64, 3, padding='same')\n",
    "    x = BasicConv2D(x, 64, 3, padding='same')\n",
    "    ra3_feat = BasicConv2D(x, 1, 3, padding='same')\n",
    "    x = tf.keras.layers.Add()([ra3_feat, crop_4])\n",
    "\n",
    "    crop_3 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='bilinear')(x)\n",
    "    x = -1 * (tf.math.sigmoid(crop_3)) + 1\n",
    "    x = tf.keras.layers.Multiply()([x, mresblock3])\n",
    "    x = BasicConv2D(x, 64, 1)\n",
    "    x = BasicConv2D(x, 64, 3, padding='same')\n",
    "    x = BasicConv2D(x, 64, 3, padding='same')\n",
    "    ra2_feat = BasicConv2D(x, 1, 3, padding='same')\n",
    "    x = tf.keras.layers.Add()([ra2_feat, crop_3])\n",
    "    lateral_map_2 = tf.keras.layers.UpSampling2D(size=(4, 4), interpolation='bilinear')(x)\n",
    "    lateral_map_2 = tf.keras.activations.sigmoid(lateral_map_2)\n",
    "\n",
    "    out_image=conv10*lateral_map_2\n",
    "\n",
    "    ##############################################################################################\n",
    "\n",
    "    model = Model(inputs, [out_image,at5_fore,at5_back,at4_fore,at4_back,at3_fore,at3_back])\n",
    "    \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T18:23:06.48679Z",
     "iopub.status.busy": "2024-09-14T18:23:06.486404Z",
     "iopub.status.idle": "2024-09-14T18:23:06.499616Z",
     "shell.execute_reply": "2024-09-14T18:23:06.498809Z",
     "shell.execute_reply.started": "2024-09-14T18:23:06.486753Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model, image_shape):\n",
    "    # make weights in the discriminator not trainable\n",
    "    for layer in d_model.layers:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False       #Descriminator layers set to untrainable in the combined GAN but \n",
    "                                                #standalone descriminator will be trainable.\n",
    "            \n",
    "    # define the source image\n",
    "    in_src = Input(shape=image_shape)\n",
    "    # suppy the image as input to the generator \n",
    "    gen_out = g_model(in_src)\n",
    "    # supply the input image and generated image as inputs to the discriminator\n",
    "    dis_out = d_model([in_src, gen_out[0]])\n",
    "    # src image as input, generated image and disc. output as outputs\n",
    "    model = Model(in_src, [dis_out, gen_out[0], gen_out[1], gen_out[2], gen_out[3], gen_out[4], gen_out[5], gen_out[6]])\n",
    "    # compile model\n",
    "    opt = Adam(learning_rate=0.00008, beta_1=0.5)\n",
    "    \n",
    "    model.compile(loss=['binary_crossentropy','binary_crossentropy','binary_crossentropy','binary_crossentropy','binary_crossentropy','binary_crossentropy','binary_crossentropy','binary_crossentropy'],optimizer=opt, loss_weights=[1,25,5,5,5,5,3,3])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T19:06:26.829744Z",
     "iopub.status.busy": "2024-09-14T19:06:26.828695Z",
     "iopub.status.idle": "2024-09-14T19:38:40.854327Z",
     "shell.execute_reply": "2024-09-14T19:38:40.85293Z",
     "shell.execute_reply.started": "2024-09-14T19:06:26.8297Z"
    },
    "trusted": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "image_shape = (512,512,3)\n",
    "# define the models\n",
    "d_model_fore = define_discriminator(image_shape)\n",
    "g_model_fore = define_generator(height=512, width=512, n_channels=3,name_prefix='f_')\n",
    "d_model_back = define_discriminator(image_shape)\n",
    "g_model_back = define_generator(height=512, width=512, n_channels=3,name_prefix='b_')\n",
    "gan_model_fore = define_gan(g_model_fore, d_model_fore, image_shape)\n",
    "gan_model_back = define_gan(g_model_back, d_model_back, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"d_model_fore:\\n\", d_model_fore.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"g_model_fore:\\n\", g_model_fore.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"d_model_back:\\n\", d_model_back.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"g_model_back:\\n\", g_model_back.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"gan_model_fore:\\n\", gan_model_fore.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"gan_model_back:\\n\", gan_model_back.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# I used one augmentation type at a time, you can do multiple\n",
    "def augment(image,mask,n):\n",
    "    aug1 = A.HorizontalFlip(p=1)\n",
    "    aug2 = A.VerticalFlip(p=1)\n",
    "    aug3 = A.OpticalDistortion(distort_limit=1, shift_limit=0.5, p=1)\n",
    "    aug4 = A.Blur(blur_limit=11, always_apply=True, p=1)\n",
    "    # @SZB: No Cutout() in albumentations, changed to CoarseDropout()\n",
    "    aug5 = A.CoarseDropout(max_holes=8, max_height=96, max_width=96, fill_value=0, always_apply=True, p=1)\n",
    "    aug6 = A.Rotate(limit=90, interpolation=1, border_mode=2, value=None, mask_value=None, rotate_method='largest_box', crop_border=False, always_apply=True, p=1)\n",
    "    aug7 = A.Downscale(scale_min=0.25, scale_max=0.25, interpolation=None, always_apply=True, p=1)\n",
    "    aug8 = A.RandomBrightnessContrast (brightness_limit=0.4, contrast_limit=0.3, brightness_by_max=True, always_apply=True, p=1)\n",
    "    aug9 = A.HueSaturationValue(hue_shift_limit=0.3, sat_shift_limit=0.4, val_shift_limit=0.3, always_apply=True, p=1)\n",
    "    aug10 = A.Affine(scale=(0.2,0.3), translate_percent=0.2, rotate=(-30,30), shear=(-45,45), always_apply=True, p=1)\n",
    "    if n==0:\n",
    "        augmented = aug10(image=image, mask=mask)\n",
    "    elif n==1:\n",
    "        augmented = aug1(image=image, mask=mask)\n",
    "    elif n==2: \n",
    "        augmented = aug2(image=image, mask=mask)\n",
    "    elif n==3: \n",
    "        augmented = aug3(image=image, mask=mask)\n",
    "    elif n==6:\n",
    "        augmented = aug6(image=image, mask=mask)\n",
    "    elif n==4: \n",
    "        augmented = aug4(image=image, mask=mask)\n",
    "    elif n==5: \n",
    "        augmented = aug5(image=image, mask=mask)\n",
    "    elif n==7:\n",
    "        return image,mask\n",
    "    elif n==8:\n",
    "        augmented = aug7(image=image, mask=mask)\n",
    "    elif n==9:\n",
    "        augmented = aug8(image=image, mask=mask)\n",
    "    elif n==10: \n",
    "        augmented = aug6(image=image, mask=mask)\n",
    "    else: \n",
    "        augmented = aug9(image=image, mask=mask)\n",
    "    \n",
    "        \n",
    "    image_aug= augmented['image']\n",
    "    mask_aug = augmented['mask']\n",
    "    return image_aug,mask_aug\n",
    "\n",
    "def generate_real_samples(data_generator,mask_generator, n_samples,patch_shape, i):\n",
    "    ix = randint(0, len(data_generator), n_samples)\n",
    "    n = i % 12\n",
    "\n",
    "    # Initialize lists to store augmented images and masks\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    X3 = []\n",
    "    X4 = []\n",
    "    X5 = []\n",
    "    X6 = []\n",
    "    X7 = []\n",
    "\n",
    "\n",
    "    for i in ix:\n",
    "        augmented_image, augmented_mask = augment(\n",
    "            numpy.reshape(data_generator[i], [512,512, 3]),  # Input image\n",
    "            numpy.reshape(mask_generator[i], [512,512, 1]),  # Input mask\n",
    "            n  # Augmentation type\n",
    "        )\n",
    "        X1.append(augmented_image)\n",
    "        X2.append(augmented_mask)\n",
    "        X3.append(1-augmented_mask)\n",
    "        X4.append(tf.image.resize(augmented_mask,(256,256)))\n",
    "        X5.append(tf.image.resize(1-augmented_mask,(256,256)))\n",
    "        X6.append(tf.image.resize(augmented_mask,(128,128)))\n",
    "        X7.append(tf.image.resize(1-augmented_mask,(128,128)))\n",
    "    y = ones((n_samples, patch_shape, patch_shape, 1))\n",
    "    return [numpy.array(X1), numpy.array(X2), numpy.array(X3), numpy.array(X4), numpy.array(X5), numpy.array(X6), numpy.array(X7)],y\n",
    "\n",
    "\n",
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "    # generate fake instance\n",
    "    X = g_model.predict(samples)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((X[0].shape[0], patch_shape, patch_shape, 1))\n",
    "    # print(\"X[0] shape: \", X[0].shape)\n",
    "    # print(\"y shape   : \", y.shape)\n",
    "    return X[0], y\n",
    "\n",
    "def summarize_performance(step, g_model1,g_model2):\n",
    "    filename2 = 'lesion_model_%06d.h5' % (step+1)\n",
    "    g_model1.save(filename2)\n",
    "    filename4 = 'background_model_%06d.h5' % (step+1)\n",
    "    g_model2.save(filename4)\n",
    "    print('>Saved: %s and %s' % (filename2,filename4))\n",
    "\n",
    "def remove_prev_performance(score_epoch):\n",
    "    filename3 = 'lesion_model_%06d.h5' % (score_epoch)\n",
    "    filename5 = 'background_model_%06d.h5' % (score_epoch)\n",
    "    filepath3 = \"training_data/\" + filename3\n",
    "    filepath5 = \"training_data/\" + filename5\n",
    "    \n",
    "    if os.path.exists(filepath3):\n",
    "        os.remove(filepath3)\n",
    "        print(f'>Removed: {filename3}')\n",
    "    else:\n",
    "        print(f'>File {filename3} does not exist')\n",
    "        \n",
    "    if os.path.exists(filepath5):\n",
    "        os.remove(filepath5)\n",
    "        print(f'>Removed: {filename5}')\n",
    "    else:\n",
    "        print(f'>File {filename5} does not exist')\n",
    "\n",
    "# def summarize_performancet(step, g_model1,g_model2,d_model1,d_model2):\n",
    "#     filename2 = 'lesion_model_%06d.h5' % (step+1)\n",
    "#     g_model1.save(filename2)\n",
    "#     filename4 = 'background_model_%06d.h5' % (step+1)\n",
    "#     g_model2.save(filename4)\n",
    "#     filename1 = 'lesion_dis_%06d.h5' % (step+1)\n",
    "#     d_model1.save(filename1)\n",
    "#     filename3 = 'background_dis_%06d.h5' % (step+1)\n",
    "#     d_model2.save(filename3)\n",
    "#     print('>Saved: %s and %s , %s and %s' % (filename2,filename4,filename1,filename3))\n",
    "# def remove_prev_performancet(score_epoch):\n",
    "#     filename3 = 'lesion_model_%06d.h5' % (score_epoch)\n",
    "#     filename5 = 'background_model_%06d.h5' % (score_epoch)\n",
    "#     filename7 = 'lesion_dis_%06d.h5' % (score_epoch)\n",
    "#     filename9 = 'background_dis_%06d.h5' % (score_epoch)\n",
    "#     os.remove(\"/kaggle/working/\"+filename3)\n",
    "#     os.remove(\"/kaggle/working/\"+filename5)\n",
    "#     os.remove(\"/kaggle/working/\"+filename7)\n",
    "#     os.remove(\"/kaggle/working/\"+filename9)\n",
    "#     print('>Removed: %s and %s, %s and %s and updated' % (filename3,filename5,filename7,filename9))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 517 validated image filenames.\n",
      "Found 65 validated image filenames.\n",
      "Found 65 validated image filenames.\n",
      "Found 517 validated image filenames.\n",
      "Found 65 validated image filenames.\n",
      "Found 65 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train1p = 'datasets/BUSI/train_folder/img'\n",
    "train2p = 'datasets/BUSI/train_folder/label'\n",
    "val1p = 'datasets/BUSI/val_folder/img'\n",
    "val2p = 'datasets/BUSI/val_folder/label'\n",
    "test1p = 'datasets/BUSI/test_folder/img'\n",
    "test2p = 'datasets/BUSI/test_folder/label'\n",
    "\n",
    "train1 = 'datasets/BUSI/train_folder/img/'\n",
    "train2 = 'datasets/BUSI/train_folder/label/'\n",
    "val1 = 'datasets/BUSI/val_folder/img/'\n",
    "val2 = 'datasets/BUSI/val_folder/label/'\n",
    "test1 = 'datasets/BUSI/test_folder/img/'\n",
    "test2 = 'datasets/BUSI/test_folder/label/'\n",
    "\n",
    "train1 = glob.glob(train1+ '/*.png')  # Adjust the file extension if needed\n",
    "train2 = glob.glob(train2 + '/*.png')\n",
    "val1 = glob.glob(val1 + '/*.png')\n",
    "val2 =glob.glob(val2 + '/*.png')\n",
    "test1=glob.glob(test1 + '/*.png')\n",
    "test2=glob.glob(test2 + '/*.png')\n",
    "\n",
    "train1 = natsort.natsorted(train1)\n",
    "train2 = natsort.natsorted(train2)\n",
    "val1 = natsort.natsorted(val1)\n",
    "val2 = natsort.natsorted(val2)\n",
    "test1 = natsort.natsorted(test1)\n",
    "test2 = natsort.natsorted(test2)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_image_train = pd.DataFrame(train1, columns=['path'])\n",
    "df_mask_train = pd.DataFrame(train2, columns=['path'])\n",
    "df_image_val = pd.DataFrame(val1, columns=['path'])\n",
    "df_mask_val = pd.DataFrame(val2, columns=['path'])\n",
    "df_image_test = pd.DataFrame(test1, columns=['path'])\n",
    "df_mask_test = pd.DataFrame(test2, columns=['path'])\n",
    "\n",
    "imggen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = imggen.flow_from_dataframe(\n",
    "    dataframe=df_image_train,\n",
    "    x_col='path',\n",
    "    y_col=None,\n",
    "    # directory=train1p,\n",
    "    target_size=(512,512),\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "test_data_generator = imggen.flow_from_dataframe(\n",
    "    dataframe=df_image_test,\n",
    "    x_col='path',\n",
    "    y_col=None,\n",
    "    # directory=test1p,\n",
    "    target_size=(512,512),\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "valid_data_generator = imggen.flow_from_dataframe(\n",
    "    dataframe=df_image_val,\n",
    "    x_col='path',\n",
    "    y_col=None,\n",
    "    # directory=val1p,\n",
    "    target_size=(512,512),\n",
    "    color_mode='rgb',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "\n",
    "# Create ImageDataGenerator for masks\n",
    "mask_data_generator = imggen.flow_from_dataframe(\n",
    "    dataframe=df_mask_train,\n",
    "    x_col='path',\n",
    "    y_col=None,\n",
    "    # directory=train2p,\n",
    "    target_size=(512,512),\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "mask_data_generator_test = imggen.flow_from_dataframe(\n",
    "    dataframe=df_mask_test,\n",
    "    x_col='path',\n",
    "    y_col=None,\n",
    "    # directory=test2p,\n",
    "    target_size=(512,512),\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "mask_data_generator_valid = imggen.flow_from_dataframe(\n",
    "    dataframe=df_mask_val,\n",
    "    x_col='path',\n",
    "    y_col=None,\n",
    "    # directory=val2p,\n",
    "    target_size=(512,512),\n",
    "    color_mode='grayscale',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    interpolation='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def log_ssim_mse_loss(y_true, y_pred, alpha=0.4):\n",
    "    ssim = tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    loss = -tf.math.log(ssim) * alpha + mse * (1 - alpha)\n",
    "    return loss*5\n",
    "\n",
    "def boundary_loss(y_true, y_pred):\n",
    "    # Compute the gradient of the predicted and ground truth masks\n",
    "    dy_true, dx_true = tf.image.image_gradients(y_true)\n",
    "    dy_pred, dx_pred = tf.image.image_gradients(y_pred)\n",
    "\n",
    "    # Compute the boundary term of the loss function\n",
    "    term_1 = tf.abs(tf.reduce_mean(tf.abs(dy_true) - tf.abs(dy_pred)))\n",
    "    term_2 = tf.abs(tf.reduce_mean(tf.abs(dx_true) - tf.abs(dx_pred)))\n",
    "\n",
    "    # Return the sum of the two terms as the boundary loss\n",
    "    return (term_1 + term_2)*5\n",
    "\n",
    "\n",
    "def mae_loss(y_true, y_pred):\n",
    "    return mean_absolute_error(tf.reshape(y_true, [-1]), tf.reshape(y_pred, [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "class LearningRateSchedulerWithPatienceIoU(Callback):\n",
    "    def __init__(self, reduce_lr_factor, patience, min_lr, monitor='val_iou',model= None):\n",
    "        super(LearningRateSchedulerWithPatienceIoU, self).__init__()\n",
    "        self.reduce_lr_factor = reduce_lr_factor\n",
    "        self.patience = patience\n",
    "        self.min_lr = min_lr\n",
    "        self.monitor = monitor\n",
    "        self.wait = 0\n",
    "        self.best_iou = -float('inf')\n",
    "        self.model = model\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_iou = logs.get(self.monitor, -float('inf'))\n",
    "\n",
    "        if current_iou > self.best_iou:\n",
    "            self.best_iou = current_iou\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                new_lr = self.model.optimizer.lr.numpy() * self.reduce_lr_factor\n",
    "                new_lr = max(new_lr, self.min_lr)\n",
    "                self.model.optimizer.lr.assign(new_lr)\n",
    "                print(f\"\\nReduced learning rate to {new_lr} after {self.patience} epochs without improvement in IoU.\\n\")\n",
    "                self.wait = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "def train(d_model, g_model, gan_model,d_model2,g_model2,gan_model2, train_data_generator,mask_data_generator, n_epochs=100, n_batch=1):\n",
    "    n_patch = d_model.output_shape[1]\n",
    "    bat_per_epo = int(len(train_data_generator)/ n_batch)\n",
    "    # calculate the number of training iterations\n",
    "    n_steps = bat_per_epo * n_epochs\n",
    "    print('starting')\n",
    "    dloss11=[]\n",
    "    dloss21=[]\n",
    "    gloss1=[]\n",
    "    score1=[]\n",
    "    Bdloss11=[]\n",
    "    Bdloss21=[]\n",
    "    rloss11=[]\n",
    "    Bgloss1=[]\n",
    "    Bscore1=[]\n",
    "    merge_score=[]\n",
    "    epochss=[]\n",
    "    epochss = list(range(0,n_epochs))\n",
    "    score_max=0\n",
    "    score_epoch=0\n",
    "    # manually enumerate epochs\n",
    "    for j in range(n_epochs):\n",
    "        dloss1=[]\n",
    "        dloss2=[]\n",
    "        gloss=[]\n",
    "        Bdloss1=[]\n",
    "        Bdloss2=[]\n",
    "        Bgloss=[]\n",
    "        rloss=[]\n",
    "        iou_score=[]\n",
    "        iou_scoreB=[]\n",
    "        iou_score_merge=[]\n",
    "        maxv1=0\n",
    "        count1=0\n",
    "        maxv2=0\n",
    "        count2=0\n",
    "        for i in range(bat_per_epo):\n",
    "        ##for lesion\n",
    "        # select a batch of real samples\n",
    "            [X_realA, X_realB, X_realC,X_realB256,X_realC256,X_realB128,X_realC128], y_real = generate_real_samples(train_data_generator,mask_data_generator, n_batch, n_patch,i)\n",
    "        # generate a batch of fake samples\n",
    "            X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "            X_fakeC, y_fake = generate_fake_samples(g_model2, X_realA, n_patch)\n",
    "        # Checking shapes\n",
    "            print(\"shape of X_realA: \",X_realA.shape)\n",
    "            print(\"shape of X_realB: \",X_realB.shape)\n",
    "            print(\"shape of X_realC: \",X_realC.shape)\n",
    "            print(\"shape of X_fakeB: \",X_fakeB.shape)\n",
    "            print(\"shape of X_fakeC: \",X_fakeC.shape)\n",
    "            print(\"shape of y_real : \",y_real.shape)\n",
    "            print(\"shape of y_fake : \",y_fake.shape)\n",
    "        # update discriminator for real samples\n",
    "            d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "        # update discriminator for generated samples\n",
    "            d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "            \n",
    "            Bd_loss1 = d_model2.train_on_batch([X_realA, X_realC], y_real)\n",
    "        # update discriminator for generated samples\n",
    "            Bd_loss2 = d_model2.train_on_batch([X_realA, X_fakeC], y_fake)\n",
    "        # update the generator\n",
    "        \n",
    "            X_realA_s = (X_realA)\n",
    "            X_fakeB1 = (X_fakeB)\n",
    "            X_fakeB1 = numpy.around(X_fakeB1)\n",
    "            BX_fakeB1 = (X_fakeC)\n",
    "            BX_fakeB1 = numpy.around(BX_fakeB1)\n",
    "            X_fakeBnew = tf.cast(numpy.logical_or(X_fakeB1,BX_fakeB1), tf.float32) \n",
    "            X_realA_recons = tf.cast(numpy.multiply(X_realA_s,X_fakeBnew),tf.float32)\n",
    "            BX_fakeB2 = (1-X_fakeC)\n",
    "            BX_fakeB2 = (BX_fakeB2)\n",
    "            BX_fakeB2 = numpy.around(BX_fakeB2)\n",
    "            X_fakeBnew2 = tf.cast(numpy.logical_and(X_fakeB1,BX_fakeB2), tf.float32) \n",
    "            reconstruction_loss = log_ssim_mse_loss(X_realA_s, X_realA_recons) + (tf.keras.backend.mean(tf.keras.losses.MAE( tf.cast(X_realB, tf.float32), X_fakeBnew2))*2) + boundary_loss(tf.cast(X_realB, tf.float32), X_fakeBnew2)\n",
    "            gan_model.add_loss(lambda:reconstruction_loss)\n",
    "            gan_model2.add_loss(lambda:reconstruction_loss)  \n",
    "            \n",
    "            \n",
    "            g_loss, _, _, _, _, _, _ , _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB,X_realB,X_realB,X_realB256,X_realC256,X_realB128,X_realB128])\n",
    "            Bg_loss, _, _, _, _, _, _, _, _ = gan_model2.train_on_batch(X_realA, [y_real, X_realC,X_realC,X_realC,X_realB256,X_realC256,X_realC128,X_realC128])\n",
    "\n",
    "\n",
    "            dloss1.append(d_loss1)\n",
    "            dloss2.append(d_loss2)\n",
    "            gloss.append(g_loss)\n",
    "            rloss.append(reconstruction_loss)\n",
    "            Bdloss1.append(Bd_loss1)\n",
    "            Bdloss2.append(Bd_loss2)\n",
    "            Bgloss.append(Bg_loss)\n",
    "\n",
    "        test_iou_score1and=[]\n",
    "        test_iou_score1or=[]\n",
    "        testf=[]\n",
    "        testb=[]\n",
    "        l=0\n",
    "        for l in range(len(test_data_generator)):\n",
    "            output=tf.reshape(test_data_generator[l], [1, 512,512, 3])\n",
    "            gen_lesion_image1 = g_model.predict(output)\n",
    "            gen_back_image1 = g_model2.predict(output)\n",
    "            gen_lesion_image1 = (gen_lesion_image1[0])\n",
    "            gen_lesion_image1 = numpy.around(gen_lesion_image1)\n",
    "            gen_back_image1 = (1-gen_back_image1[0])\n",
    "            gen_back_image1 = numpy.around(gen_back_image1)\n",
    "            \n",
    "            tar_image1 = numpy.around(mask_data_generator_test[l])\n",
    "            gen_image1 = numpy.logical_and(gen_lesion_image1,gen_back_image1 )\n",
    "            gen_image1or = numpy.logical_or(gen_lesion_image1,gen_back_image1 )\n",
    "            intersection1 = numpy.logical_and(gen_image1, tar_image1)+0.00001\n",
    "            union1 = numpy.logical_or(gen_image1, tar_image1)+0.00001\n",
    "            test_iou_score1and.append(numpy.sum(intersection1) / numpy.sum(union1))\n",
    "            intersection1or = numpy.logical_and(gen_image1or, tar_image1)+0.00001\n",
    "            union1or = numpy.logical_or(gen_image1or, tar_image1)+0.00001\n",
    "            test_iou_score1or.append(numpy.sum(intersection1or) / numpy.sum(union1or))\n",
    "        test_iou_score2and=numpy.mean(test_iou_score1and)\n",
    "        test_iou_score2or=numpy.mean(test_iou_score1or)\n",
    "        \n",
    "        valid_iou_score1and=[]\n",
    "        valid_iou_score1or=[]\n",
    "        l=0\n",
    "        for l in range(len(valid_data_generator)):\n",
    "            output=tf.reshape(valid_data_generator[l], [1, 512,512, 3])\n",
    "            gen_lesion_image1 = g_model.predict(output)\n",
    "            gen_back_image1 = g_model2.predict(output)\n",
    "            gen_lesion_image1 = (gen_lesion_image1[0])\n",
    "            gen_lesion_image1 = numpy.around(gen_lesion_image1)\n",
    "            gen_back_image1 = (1-gen_back_image1[0])\n",
    "            gen_back_image1 = numpy.around(gen_back_image1)\n",
    "            \n",
    "            tar_image1 = numpy.around(mask_data_generator_valid[l])\n",
    "            gen_image1 = numpy.logical_and(gen_lesion_image1,gen_back_image1 )\n",
    "            gen_image1or = numpy.logical_or(gen_lesion_image1,gen_back_image1)\n",
    "            intersection1 = numpy.logical_and(gen_image1, tar_image1)+0.00001\n",
    "            union1 = numpy.logical_or(gen_image1, tar_image1)+0.00001\n",
    "            valid_iou_score1and.append(numpy.sum(intersection1) / numpy.sum(union1))\n",
    "            intersection1or = numpy.logical_and(gen_image1or, tar_image1)+0.00001\n",
    "            union1or = numpy.logical_or(gen_image1or, tar_image1)+0.00001\n",
    "            valid_iou_score1or.append(numpy.sum(intersection1or) / numpy.sum(union1or))\n",
    "        valid_iou_score2and=numpy.mean(valid_iou_score1and)\n",
    "        valid_iou_score2or=numpy.mean(valid_iou_score1or)\n",
    "        \n",
    "        lr_scheduler_f.on_epoch_end(j+1, {'val_iou': max(valid_iou_score2and,valid_iou_score2or)})\n",
    "        lr_scheduler_b.on_epoch_end(j+1, {'val_iou': max(valid_iou_score2and,valid_iou_score2or)})\n",
    "\n",
    "        dloss1m=numpy.mean(dloss1)\n",
    "        dloss2m=numpy.mean(dloss2)\n",
    "        glossm=numpy.mean(gloss)\n",
    "        Bdloss1m=numpy.mean(Bdloss1)\n",
    "        Bdloss2m=numpy.mean(Bdloss2)\n",
    "        rlossm=numpy.mean(rloss)\n",
    "        Bglossm=numpy.mean(Bgloss)\n",
    "        print('Epoch %d> d1[%.3f] d2[%.3f]  g[%.3f] Bd1[%.3f] Bd2[%.3f]  Bg[%.3f]  r[%.3f] valid and:[%.3f] valid or:[%.3f]  test_iou_and:[%.5f] test_iou_OR:[%.5f]' % (j+1, dloss1m, dloss2m, glossm,Bdloss1m, Bdloss2m,  Bglossm,rlossm, valid_iou_score2and,valid_iou_score2or,test_iou_score2and,test_iou_score2or))\n",
    "        dloss11.append(dloss1m)\n",
    "        dloss21.append(dloss2m)\n",
    "        gloss1.append(glossm)\n",
    "        Bdloss11.append(Bdloss1m)\n",
    "        Bdloss21.append(Bdloss2m)\n",
    "        rloss11.append(rlossm)\n",
    "        Bgloss1.append(Bglossm)\n",
    "        # summarize performance\n",
    "        # best validation score based decision\n",
    "        if max(valid_iou_score2and,valid_iou_score2or)>=score_max:\n",
    "            summarize_performance((j), g_model,g_model2)\n",
    "            if j!=0:\n",
    "                remove_prev_performance(score_epoch)\n",
    "            score_max=max(valid_iou_score2and,valid_iou_score2or)\n",
    "            score_epoch=j+1\n",
    "        # best test score based decision\n",
    "        if max(test_iou_score2and,test_iou_score2or)>=score_max:\n",
    "            summarize_performance((j), g_model,g_model2)\n",
    "            if j!=0:\n",
    "                remove_prev_performance(score_epoch)\n",
    "            score_max=max(test_iou_score2and,test_iou_score2or)\n",
    "            score_epoch=j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.00008  # Initial learning rate\n",
    "reduce_lr_factor = 0.5  # Factor by which to reduce the learning rate\n",
    "patience = 30  # Number of epochs without improvement in IoU before reducing learning rate\n",
    "min_learning_rate = 1e-8  # Minimum learning rate\n",
    "\n",
    "# Create the custom learning rate scheduler\n",
    "lr_scheduler_f = LearningRateSchedulerWithPatienceIoU(reduce_lr_factor, patience, min_learning_rate,model=gan_model_fore)\n",
    "lr_scheduler_b = LearningRateSchedulerWithPatienceIoU(reduce_lr_factor, patience, min_learning_rate,model=gan_model_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# start1 = datetime.now() \n",
    "\n",
    "# train(d_model_fore, g_model_fore, gan_model_fore,d_model_back,g_model_back,gan_model_back,train_data_generator,mask_data_generator, n_epochs=300, n_batch=1) \n",
    "\n",
    "# stop1 = datetime.now()\n",
    "# #Execution time of the model \n",
    "# execution_time = stop1-start1\n",
    "# print(\"Execution time is: \", execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1, Batch Size: 2, Batches per epoch: 258, Steps: 258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 10s 10s/step\n",
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_4/model_1/lambda_9/concat' defined at (most recent call last):\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_581062/402939128.py\", line 79, in <module>\n      g_loss, _, _, _, _, _, _ , _, _ = gan_model_fore.train_on_batch(X_realA, [y_real, X_realB,X_realB,X_realB,X_realB256,X_realC256,X_realB128,X_realB128])\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 2478, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/layers/core/lambda_layer.py\", line 209, in call\n      result = self.function(inputs, **kwargs)\n    File \"/tmp/ipykernel_581062/1131017510.py\", line 24, in <lambda>\n      return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),arguments={'repnum': rep})(tensor)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/backend.py\", line 3771, in repeat_elements\n      return concatenate(x_rep, axis)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/backend.py\", line 3572, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model_4/model_1/lambda_9/concat'\nOOM when allocating tensor with shape[2,512,512,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_4/model_1/lambda_9/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_202273]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m gan_model_fore\u001b[38;5;241m.\u001b[39madd_loss(\u001b[38;5;28;01mlambda\u001b[39;00m:reconstruction_loss)\n\u001b[1;32m     77\u001b[0m gan_model_back\u001b[38;5;241m.\u001b[39madd_loss(\u001b[38;5;28;01mlambda\u001b[39;00m:reconstruction_loss)\n\u001b[0;32m---> 79\u001b[0m g_loss, _, _, _, _, _, _ , _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgan_model_fore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_realA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43my_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_realB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_realB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_realB\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_realB256\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_realC256\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_realB128\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_realB128\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m Bg_loss, _, _, _, _, _, _, _, _ \u001b[38;5;241m=\u001b[39m gan_model_back\u001b[38;5;241m.\u001b[39mtrain_on_batch(X_realA, [y_real, X_realC,X_realC,X_realC,X_realB256,X_realC256,X_realC128,X_realC128])\n\u001b[1;32m     82\u001b[0m dloss1\u001b[38;5;241m.\u001b[39mappend(d_loss1)\n",
      "File \u001b[0;32m~/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py:2478\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2474\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39msingle_batch_iterator(\n\u001b[1;32m   2475\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy, x, y, sample_weight, class_weight\n\u001b[1;32m   2476\u001b[0m     )\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[0;32m-> 2478\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_4/model_1/lambda_9/concat' defined at (most recent call last):\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n      app.start()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/asyncio/base_events.py\", line 595, in run_forever\n      self._run_once()\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/asyncio/base_events.py\", line 1881, in _run_once\n      handle._run()\n    File \"/home/wcsng-32/.pyenv/versions/3.10.0/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n      await self.process_one()\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n      await dispatch(*args)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n      await result\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n      reply_content = await reply_content\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n      res = shell.run_cell(\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n      result = self._run_cell(\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n      result = runner(coro)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_581062/402939128.py\", line 79, in <module>\n      g_loss, _, _, _, _, _, _ , _, _ = gan_model_fore.train_on_batch(X_realA, [y_real, X_realB,X_realB,X_realB,X_realB256,X_realC256,X_realB128,X_realB128])\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 2478, in train_on_batch\n      logs = self.train_function(iterator)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function\n      return step_function(self, iterator)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step\n      outputs = model.train_step(data)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/training.py\", line 561, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 511, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/functional.py\", line 668, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/engine/base_layer.py\", line 1132, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/layers/core/lambda_layer.py\", line 209, in call\n      result = self.function(inputs, **kwargs)\n    File \"/tmp/ipykernel_581062/1131017510.py\", line 24, in <lambda>\n      return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),arguments={'repnum': rep})(tensor)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/backend.py\", line 3771, in repeat_elements\n      return concatenate(x_rep, axis)\n    File \"/home/wcsng-32/balla_chua/Hi-gMISnet/pyenv/lib/python3.10/site-packages/keras/backend.py\", line 3572, in concatenate\n      return tf.concat([to_dense(x) for x in tensors], axis)\nNode: 'model_4/model_1/lambda_9/concat'\nOOM when allocating tensor with shape[2,512,512,16] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_4/model_1/lambda_9/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_202273]"
     ]
    }
   ],
   "source": [
    "n_epochs=1\n",
    "n_batch=2\n",
    "\n",
    "n_patch = d_model_fore.output_shape[1]\n",
    "bat_per_epo = int(len(train_data_generator)/ n_batch)\n",
    "# calculate the number of training iterations\n",
    "n_steps = bat_per_epo * n_epochs\n",
    "print('Epochs: %d, Batch Size: %d, Batches per epoch: %d, Steps: %d' % (n_epochs, n_batch, bat_per_epo, n_steps))\n",
    "dloss11=[]\n",
    "dloss21=[]\n",
    "gloss1=[]\n",
    "score1=[]\n",
    "Bdloss11=[]\n",
    "Bdloss21=[]\n",
    "rloss11=[]\n",
    "Bgloss1=[]\n",
    "Bscore1=[]\n",
    "merge_score=[]\n",
    "epochss=[]\n",
    "epochss = list(range(0,n_epochs))\n",
    "score_max=0\n",
    "score_epoch=0\n",
    "# manually enumerate epochs\n",
    "for j in range(n_epochs):\n",
    "    dloss1=[]\n",
    "    dloss2=[]\n",
    "    gloss=[]\n",
    "    Bdloss1=[]\n",
    "    Bdloss2=[]\n",
    "    Bgloss=[]\n",
    "    rloss=[]\n",
    "    iou_score=[]\n",
    "    iou_scoreB=[]\n",
    "    iou_score_merge=[]\n",
    "    maxv1=0\n",
    "    count1=0\n",
    "    maxv2=0\n",
    "    count2=0\n",
    "    for i in range(bat_per_epo):\n",
    "    ##for lesion\n",
    "    # select a batch of real samples\n",
    "        [X_realA, X_realB, X_realC,X_realB256,X_realC256,X_realB128,X_realC128], y_real = generate_real_samples(train_data_generator,mask_data_generator, n_batch, n_patch,i)\n",
    "    # generate a batch of fake samples\n",
    "        X_fakeB, y_fake = generate_fake_samples(g_model_fore, X_realA, n_patch)\n",
    "        X_fakeC, y_fake = generate_fake_samples(g_model_back, X_realA, n_patch)\n",
    "    # Checking shapes\n",
    "        # print(\"shape of X_realA: \",X_realA.shape)\n",
    "        # print(\"shape of X_realB: \",X_realB.shape)\n",
    "        # print(\"shape of X_realC: \",X_realC.shape)\n",
    "        # print(\"shape of X_fakeB: \",X_fakeB.shape)\n",
    "        # print(\"shape of X_fakeC: \",X_fakeC.shape)\n",
    "        # print(\"shape of y_real : \",y_real.shape)\n",
    "        # print(\"shape of y_fake : \",y_fake.shape)\n",
    "    # update discriminator for real samples\n",
    "        d_loss1 = d_model_fore.train_on_batch([X_realA, X_realB], y_real)\n",
    "    # update discriminator for generated samples\n",
    "        d_loss2 = d_model_fore.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "        \n",
    "        Bd_loss1 = d_model_back.train_on_batch([X_realA, X_realC], y_real)\n",
    "    # update discriminator for generated samples\n",
    "        Bd_loss2 = d_model_back.train_on_batch([X_realA, X_fakeC], y_fake)\n",
    "    # update the generator\n",
    "    \n",
    "        X_realA_s = (X_realA)\n",
    "        X_fakeB1 = (X_fakeB)\n",
    "        X_fakeB1 = numpy.around(X_fakeB1)\n",
    "        BX_fakeB1 = (X_fakeC)\n",
    "        BX_fakeB1 = numpy.around(BX_fakeB1)\n",
    "        X_fakeBnew = tf.cast(numpy.logical_or(X_fakeB1,BX_fakeB1), tf.float32) \n",
    "        X_realA_recons = tf.cast(numpy.multiply(X_realA_s,X_fakeBnew),tf.float32)\n",
    "        BX_fakeB2 = (1-X_fakeC)\n",
    "        BX_fakeB2 = (BX_fakeB2)\n",
    "        BX_fakeB2 = numpy.around(BX_fakeB2)\n",
    "        X_fakeBnew2 = tf.cast(numpy.logical_and(X_fakeB1,BX_fakeB2), tf.float32) \n",
    "        reconstruction_loss = log_ssim_mse_loss(X_realA_s, X_realA_recons) + (tf.keras.backend.mean(tf.keras.losses.MAE( tf.cast(X_realB, tf.float32), X_fakeBnew2))*2) + boundary_loss(tf.cast(X_realB, tf.float32), X_fakeBnew2)\n",
    "        gan_model_fore.add_loss(lambda:reconstruction_loss)\n",
    "        gan_model_back.add_loss(lambda:reconstruction_loss)\n",
    "        \n",
    "        g_loss, _, _, _, _, _, _ , _, _ = gan_model_fore.train_on_batch(X_realA, [y_real, X_realB,X_realB,X_realB,X_realB256,X_realC256,X_realB128,X_realB128])\n",
    "        Bg_loss, _, _, _, _, _, _, _, _ = gan_model_back.train_on_batch(X_realA, [y_real, X_realC,X_realC,X_realC,X_realB256,X_realC256,X_realC128,X_realC128])\n",
    "\n",
    "        dloss1.append(d_loss1)\n",
    "        dloss2.append(d_loss2)\n",
    "        gloss.append(g_loss)\n",
    "        rloss.append(reconstruction_loss)\n",
    "        Bdloss1.append(Bd_loss1)\n",
    "        Bdloss2.append(Bd_loss2)\n",
    "        Bgloss.append(Bg_loss)\n",
    "\n",
    "    # test_iou_score1and=[]\n",
    "    # test_iou_score1or=[]\n",
    "    # testf=[]\n",
    "    # testb=[]\n",
    "    # l=0\n",
    "    # for l in range(len(test_data_generator)):\n",
    "    #     output=tf.reshape(test_data_generator[l], [1, 512,512, 3])\n",
    "    #     gen_lesion_image1 = g_model_fore.predict(output)\n",
    "    #     gen_back_image1 = g_model_back.predict(output)\n",
    "    #     gen_lesion_image1 = (gen_lesion_image1[0])\n",
    "    #     gen_lesion_image1 = numpy.around(gen_lesion_image1)\n",
    "    #     gen_back_image1 = (1-gen_back_image1[0])\n",
    "    #     gen_back_image1 = numpy.around(gen_back_image1)\n",
    "        \n",
    "    #     tar_image1 = numpy.around(mask_data_generator_test[l])\n",
    "    #     gen_image1 = numpy.logical_and(gen_lesion_image1,gen_back_image1 )\n",
    "    #     gen_image1or = numpy.logical_or(gen_lesion_image1,gen_back_image1 )\n",
    "    #     intersection1 = numpy.logical_and(gen_image1, tar_image1)+0.00001\n",
    "    #     union1 = numpy.logical_or(gen_image1, tar_image1)+0.00001\n",
    "    #     test_iou_score1and.append(numpy.sum(intersection1) / numpy.sum(union1))\n",
    "    #     intersection1or = numpy.logical_and(gen_image1or, tar_image1)+0.00001\n",
    "    #     union1or = numpy.logical_or(gen_image1or, tar_image1)+0.00001\n",
    "    #     test_iou_score1or.append(numpy.sum(intersection1or) / numpy.sum(union1or))\n",
    "    # test_iou_score2and=numpy.mean(test_iou_score1and)\n",
    "    # test_iou_score2or=numpy.mean(test_iou_score1or)\n",
    "    \n",
    "    # valid_iou_score1and=[]\n",
    "    # valid_iou_score1or=[]\n",
    "    # l=0\n",
    "    # for l in range(len(valid_data_generator)):\n",
    "    #     output=tf.reshape(valid_data_generator[l], [1, 512,512, 3])\n",
    "    #     gen_lesion_image1 = g_model_fore.predict(output)\n",
    "    #     gen_back_image1 = g_model_back.predict(output)\n",
    "    #     gen_lesion_image1 = (gen_lesion_image1[0])\n",
    "    #     gen_lesion_image1 = numpy.around(gen_lesion_image1)\n",
    "    #     gen_back_image1 = (1-gen_back_image1[0])\n",
    "    #     gen_back_image1 = numpy.around(gen_back_image1)\n",
    "        \n",
    "    #     tar_image1 = numpy.around(mask_data_generator_valid[l])\n",
    "    #     gen_image1 = numpy.logical_and(gen_lesion_image1,gen_back_image1 )\n",
    "    #     gen_image1or = numpy.logical_or(gen_lesion_image1,gen_back_image1)\n",
    "    #     intersection1 = numpy.logical_and(gen_image1, tar_image1)+0.00001\n",
    "    #     union1 = numpy.logical_or(gen_image1, tar_image1)+0.00001\n",
    "    #     valid_iou_score1and.append(numpy.sum(intersection1) / numpy.sum(union1))\n",
    "    #     intersection1or = numpy.logical_and(gen_image1or, tar_image1)+0.00001\n",
    "    #     union1or = numpy.logical_or(gen_image1or, tar_image1)+0.00001\n",
    "    #     valid_iou_score1or.append(numpy.sum(intersection1or) / numpy.sum(union1or))\n",
    "    # valid_iou_score2and=numpy.mean(valid_iou_score1and)\n",
    "    # valid_iou_score2or=numpy.mean(valid_iou_score1or)\n",
    "    \n",
    "    # lr_scheduler_f.on_epoch_end(j+1, {'val_iou': max(valid_iou_score2and,valid_iou_score2or)})\n",
    "    # lr_scheduler_b.on_epoch_end(j+1, {'val_iou': max(valid_iou_score2and,valid_iou_score2or)})\n",
    "\n",
    "    # dloss1m=numpy.mean(dloss1)\n",
    "    # dloss2m=numpy.mean(dloss2)\n",
    "    # glossm=numpy.mean(gloss)\n",
    "    # Bdloss1m=numpy.mean(Bdloss1)\n",
    "    # Bdloss2m=numpy.mean(Bdloss2)\n",
    "    # rlossm=numpy.mean(rloss)\n",
    "    # Bglossm=numpy.mean(Bgloss)\n",
    "    # print('Epoch %d> d1[%.3f] d2[%.3f]  g[%.3f] Bd1[%.3f] Bd2[%.3f]  Bg[%.3f]  r[%.3f] valid and:[%.3f] valid or:[%.3f]  test_iou_and:[%.5f] test_iou_OR:[%.5f]' % (j+1, dloss1m, dloss2m, glossm,Bdloss1m, Bdloss2m,  Bglossm,rlossm, valid_iou_score2and,valid_iou_score2or,test_iou_score2and,test_iou_score2or))\n",
    "    # dloss11.append(dloss1m)\n",
    "    # dloss21.append(dloss2m)\n",
    "    # gloss1.append(glossm)\n",
    "    # Bdloss11.append(Bdloss1m)\n",
    "    # Bdloss21.append(Bdloss2m)\n",
    "    # rloss11.append(rlossm)\n",
    "    # Bgloss1.append(Bglossm)\n",
    "    # # summarize performance\n",
    "    # # best validation score based decision\n",
    "    # if max(valid_iou_score2and,valid_iou_score2or)>=score_max:\n",
    "    #     summarize_performance((j), g_model_fore,g_model_back)\n",
    "    #     if j!=0:\n",
    "    #         remove_prev_performance(score_epoch)\n",
    "    #     score_max=max(valid_iou_score2and,valid_iou_score2or)\n",
    "    #     score_epoch=j+1\n",
    "    # # best test score based decision\n",
    "    # if max(test_iou_score2and,test_iou_score2or)>=score_max:\n",
    "    #     summarize_performance((j), g_model_fore,g_model_back)\n",
    "    #     if j!=0:\n",
    "    #         remove_prev_performance(score_epoch)\n",
    "    #     score_max=max(test_iou_score2and,test_iou_score2or)\n",
    "    #     score_epoch=j+1"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2378526,
     "sourceId": 4012349,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2591346,
     "sourceId": 4424093,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2887789,
     "sourceId": 4981332,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3209844,
     "sourceId": 5576509,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3263240,
     "sourceId": 5676529,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3324210,
     "sourceId": 5785734,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3332587,
     "sourceId": 5810159,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3405163,
     "sourceId": 6278110,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3694983,
     "isSourceIdPinned": true,
     "sourceId": 6412452,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3414950,
     "sourceId": 6412997,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3793236,
     "sourceId": 6570033,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30302,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
